{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 210C (Jonannes) Homework 2 by Mikey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I use R for the code in this assignment, which is not built into VSCode by default. In order to run this code, you may need to download R, add the R extension to VSCode, and then run the following in a terminal:_\n",
    "\n",
    "```\n",
    "R -e 'install.packages(\"IRkernel\", repos=\"https://cloud.r-project.org/\")'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARs\n",
    "### Download data for the Federal Funds Rate, the civilian unemployment rate, and the GDP deflator inflation rate from FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Clear all.\n",
    "rm(list = ls())\n",
    "\n",
    "install.packages(\"quantmod\")\n",
    "library(quantmod)\n",
    "\n",
    "# Import Federal Funds Rate, Unemployment Rate, and GDP Deflator Inflation rate data from FRED.\n",
    "R <- getSymbols(\"FEDFUNDS\", src = \"FRED\", auto.assign = FALSE)\n",
    "u <- getSymbols(\"UNRATE\", src = \"FRED\", auto.assign = FALSE)\n",
    "pi <- getSymbols(\"GDPDEF\", src = \"FRED\", auto.assign = FALSE)\n",
    "\n",
    "#Put the data into data frames.\n",
    "R <- data.frame(date = index(R), R = coredata(R)[, \"FEDFUNDS\"])\n",
    "u <- data.frame(date = index(u), u = coredata(u)[, \"UNRATE\"])\n",
    "pi <- data.frame(date = index(pi), pi = coredata(pi)[, \"GDPDEF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Plot the data. Make sure all graphs are appropriately labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "\n",
    "ggplot(R, aes(x = date, y = R)) + geom_line() + labs(title = \"Federal Funds Rate\", x = \"Date\", y = \"Percentage Points\")\n",
    "ggplot(u, aes(x = date, y = u)) + geom_line() + labs(title = \"Unemployment Rate\", x = \"Date\", y = \"Percentage Points\")\n",
    "ggplot(pi, aes(x = date, y = pi)) + geom_line() + labs(title = \"GDP Deflator Inflation Rate\", x = \"Date\", y = \"Percentage Points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (b) Aggregate all series to a quarterly frequency by averaging over months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "R <- aggregate(R$R, list(yearqtr = as.yearqtr(R$date)), mean)\n",
    "u <- aggregate(u$u, list(yearqtr = as.yearqtr(u$date)), mean)\n",
    "pi <- aggregate(pi$pi, list(yearqtr = as.yearqtr(pi$date)), mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate a VAR with 4 lags from 1960Q1:2007Q4. The ordering of your variables should be $\\pi_t,u_t,R_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"vars\")\n",
    "library(vars)\n",
    "\n",
    "# Merge the data into a single data frame\n",
    "data <- merge(pi, merge(u, R, by = \"yearqtr\"), by = \"yearqtr\")\n",
    "colnames(data) <- c(\"yearqtr\", \"pi\", \"u\", \"R\")\n",
    "\n",
    "# Calculate inflation\n",
    "library(dplyr)\n",
    "data$pi <- 100 * (data$pi - lag(data$pi, 4)) / lag(data$pi, 4)\n",
    "\n",
    "# Filter the data to keep observations from 1960Q1 to 2007Q4\n",
    "start_date <- as.yearqtr(\"1960 Q1\")\n",
    "end_date <- as.yearqtr(\"2007 Q4\")\n",
    "data_filtered <- data[data$yearqtr >= start_date & data$yearqtr <= end_date, ]\n",
    "\n",
    "# Convert the filtered data to a time series object with quarterly frequency\n",
    "time_series <- ts(data_filtered[, c(\"pi\", \"u\", \"R\")], start = c(1960, 1), end = c(2007, 4), frequency = 4)\n",
    "\n",
    "# Estimate the VAR model with 4 lags\n",
    "var_model <- VAR(time_series, p = 4, type = \"const\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Briefly, explain why it would make sense to end the sample in 2007Q4?\n",
    "That is the onset of the Great Recession, which is probably the most significant economic event since the Great Depression. If we want to test the external validity of our VAR model, we can train it on data from \"steady state\" (pre-2007) and see how well it performs out of sample. Also, there was some pretty big government expenditure in response to the Great Recession, so if we train the VAR using data from that time, it may be capturing the response of the variables to this government activity (an omitted variable) rather than to natural fluctuations to the rest of the three (included) variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Plot the IRFs from the SVAR with the same ordering. [Optional: add 95\\% error bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create matrices for ordering\n",
    "A <- matrix(c(NA, 0, 0, \n",
    "               NA, NA, 0,\n",
    "               NA, NA, NA), nrow = 3, ncol = 3, byrow = TRUE)\n",
    "\n",
    "B <- diag(3)\n",
    "\n",
    "# Estimate the SVAR model using the VAR model and identification restrictions\n",
    "svar <- SVAR(var_model, Amat = A, Bmat = B, estmethod = \"direct\", lrtest = FALSE)\n",
    "\n",
    "#Calculate the Impulse Response Functions (IRFs) with bootstrapped standard errors\n",
    "irf <- irf(var_model, impulse = c(\"pi\", \"u\", \"R\"), response = c(\"pi\", \"u\", \"R\"), boot = TRUE, runs = 1000)\n",
    "\n",
    "# Set the background color to white for legibility\n",
    "par(bg = \"white\")\n",
    "\n",
    "# Plot each combination of impulse and response\n",
    "plot(irf, lwd = 3, bg = \"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Briefly, interpret your results.\n",
    "Shocks to inflation preceeds...\n",
    "* Sustained, elevated inflation;\n",
    "* Slowly increasing unemployment;\n",
    "* Sustained, elevated interest rates.\n",
    "    \n",
    "The story here sounds like that of government response: if inflation is high, the Fed responds by increasing interest rates, surpressing economic activity.\n",
    "\n",
    "Shocks to unemployment preceeds...\n",
    "* A slow dip and then slow rebound in inflation;\n",
    "* A slow dissipation of the unemployment shock;\n",
    "* A sharp decrease and slow regression of interest rates.\n",
    "\n",
    "If unemployment increases, then spending should decrease, slowing inflation. The unemployment shock is somewhat sticky, so the government responds by lowering interest rates.\n",
    "\n",
    "Shocks to interest rates preceeds...\n",
    "* Remarkably little movement in inflation;\n",
    "* A small, slow increase in unemployment;\n",
    "* A steady regression of interest rates down to the mean.\n",
    "\n",
    "This speaks to the tricky reverse causaility story. Increased interest rates are supposed to cool down an economny and prevent inflation, but if they are often used as a tool by the Fed to counteract anticipated inflation and an \"overheating\" economy, the causal effect and the reverse causal effect may cancel each other out entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Plot the time series of your identified monetary shocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the residuals (shocks) from the VAR model\n",
    "residuals <- residuals(var_model)\n",
    "\n",
    "# Adjust the dates to match the residuals (drop the initial lags)\n",
    "adjusted_dates <- data_filtered$yearqtr[-(1:4)]\n",
    "\n",
    "# Convert residuals to a data frame for plotting\n",
    "residuals_df <- data.frame(date = adjusted_dates, residuals)\n",
    "\n",
    "# Rename the columns to match the variable names\n",
    "colnames(residuals_df) <- c(\"date\", \"pi_shock\", \"u_shock\", \"R_shock\")\n",
    "\n",
    "# Set up a 3x1 plotting space\n",
    "par(mfrow = c(3, 1), mar = c(4, 4, 2, 1), bg = \"white\")  \n",
    "\n",
    "# Plot each shock time series\n",
    "plot(residuals_df$date, residuals_df$pi_shock, type = \"l\", col = \"red\", \n",
    "     xlab = \"\", ylab = \"Percentage Points\", main = \"Deviation in Inflation (pi) from VAR Prediction\")\n",
    "plot(residuals_df$date, residuals_df$R_shock, type = \"l\", col = \"blue\", \n",
    "     xlab = \"\", ylab = \"Percentage Points\", main = \"Deviation in Federal Funds Rate (R) from VAR Prediction\")\n",
    "plot(residuals_df$date, residuals_df$u_shock, type = \"l\", col = \"green\", \n",
    "     xlab = \"\", ylab = \"Percentage Points\", main = \"Deviation in Unemployment (u) from VAR Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) What are the identified monetary shocks in 2001Q3 and 2001Q4? How should one interpret these shocks?\n",
    "This is the aftermath of the September 11 attacks. To be honest, I don't see much happening in my plots, which makes me fearful that I did something wrong — inflation seems to be in line with the predictions of the model, and although unemployment is higher than predicted, the residual is not more than 0.5 percentage points. There is a somewhat notable dip in interest rates, which suggests to me that the government responded to the attacks by lowering interest rates.\n",
    "\n",
    "Although I was old enough to remember this, I was not old enough to care about what the government did in response. A brief skim of the [September 11 attacks Wikipedia page](https://en.wikipedia.org/wiki/Economic_effects_of_the_September_11_attacks) reveals that unemployment increased sharply in New York City, which would have a small but not imperceptable effect on the overall US economy and explains our result. Meanwhile, stock markets took a massive hit around the world, which explains the government response that we see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Romer shocks\n",
    "### (a) Download the Romer–Romer shocks from my website and merge it with your VAR dataset. Set the values of the Romer shocks to zero before 1969Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "setwd(\"/Users/mikey/Documents/Academic/UCSD/Macro 210C/Macro210C/HW2/\")\n",
    "install.packages(\"haven\")\n",
    "library(haven)\n",
    "romer <- read_dta(\"RR_monetary_shock_quarterly.dta\")\n",
    "\n",
    "# Convert the date variable to year-quarter format.\n",
    "start_date <- as.yearqtr(\"1960 Q1\")  # Adjust the start date if necessary\n",
    "romer$yearqtr <- as.yearqtr(start_date + romer$date/4)\n",
    "\n",
    "# Merge the datasets.\n",
    "data_merged <- merge(data_filtered, romer, by = \"yearqtr\", all.x = TRUE)\n",
    "\n",
    "# Rename resid_romer to RR\n",
    "colnames(data_merged)[colnames(data_merged) == \"resid_romer\"] <- \"RR\"\n",
    "\n",
    "# Set the values of the Romer shocks to zero before 1969Q1.\n",
    "data_merged$RR[data_merged$yearqtr < as.yearqtr(\"1969 Q1\")] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Following Romer–Romer, construct the IRF from the estimation equation\n",
    "$$\n",
    "    \\begin{equation*}\n",
    "            y_t = \\alpha + \\sum_{s=1}^{8}\\beta_s y_{t-s} + \\sum_{s=0}^{12}\\gamma_{s}RR_{t-s}\n",
    "    \\end{equation*}\n",
    "$$\n",
    "### where $y_t\\in[\\pi_t,u_t,R_t]$ are the outcome variables and $RR_t$ are the Romer shocks estimated from 1960Q1:2007Q4. [Optional: add 95\\% error bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate 12 lagged variables for RR using a loop\n",
    "for (i in 1:12) {\n",
    "  data_merged[[paste0(\"RR_\", i)]] <- lag(data_merged$RR, i)\n",
    "}\n",
    "\n",
    "# Replace NA values in data_merged with 0\n",
    "data_merged[is.na(data_merged)] <- 0\n",
    "\n",
    "# Define RR_lags as a vector of RR and all its lags.\n",
    "RR_lags <- c(\"RR\", paste0(\"RR_\", 1:12))\n",
    "\n",
    "# Convert RR_lags to a matrix and replace NAs with zeros\n",
    "RR_lags_mat <- as.matrix(data_merged[, RR_lags])\n",
    "RR_lags_mat[is.na(RR_lags_mat)] <- 0\n",
    "\n",
    "# Create time series with variables in correct order.\n",
    "time_series_romer <- ts(data_merged[, c(\"pi\", \"u\", \"R\")], start = c(1960, 1), end = c(2007, 4), frequency = 4)\n",
    "time_series_romer[is.na(time_series_romer)] <- 0\n",
    "\n",
    "# VAR it up.\n",
    "var_romer <- VAR(time_series_romer, p = 8, type = \"const\", exogen = RR_lags_mat)\n",
    "\n",
    "#IRFs (with bootstrapped standard errors)\n",
    "irf_romer <- irf(var_romer, impulse = c(\"pi\", \"u\", \"R\"), response = c(\"pi\", \"u\", \"R\"), boot = TRUE, runs = 1000, n.ahead = 10)\n",
    "par(bg = \"white\")\n",
    "plot(irf_romer, lwd = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Now estimate an SVAR ordered $RR_t,\\pi_t,u_t,R_t$ with four lags from 1960Q1:2007Q4 and plot the IRFs. [Optional: add 95\\% error bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create time series with variables in correct order.\n",
    "time_series_romer <- ts(data_merged[, c(\"RR\", \"pi\", \"u\", \"R\" )], start = c(1960, 1), end = c(2007, 4), frequency = 4)\n",
    "\n",
    "# Estimate the VAR model on which this SVAR will be based.\n",
    "var_romer <- VAR(time_series_romer, p = 4, type = \"const\")\n",
    "\n",
    "# Create matrices for ordering.\n",
    "AA <- matrix(c(NA, 0, 0, 0, \n",
    "               NA, NA, 0, 0, \n",
    "               NA, NA, NA, 0, \n",
    "               NA, NA, NA, NA), nrow = 4, ncol = 4, byrow = TRUE)\n",
    "\n",
    "BB <- diag(4)\n",
    "\n",
    "# Estimate the SVAR model using the VAR model and identification restrictions.\n",
    "svar_romer <- SVAR(var_romer, Amat = AA, Bmat = BB, estmethod = \"direct\", lrtest = FALSE)\n",
    "\n",
    "#IRFs (with bootstrapped standard errors)\n",
    "irf_svar_romer <- irf(svar_romer, impulse = c(\"pi\", \"u\", \"R\", \"RR\"), response = c(\"pi\", \"u\", \"R\", \"RR\"), boot = TRUE, runs = 1000, n.ahead = 10)\n",
    "par(bg = \"white\")\n",
    "plot(irf_svar_romer, lwd = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Briefly, explain why it is sensible to order the Romer shock first in the VAR.\n",
    "Romer and Romer (2023) documents changes in monetary policy that are \"not taken in response to current or prospective developments in real activity.\" As we are on a quest for exogenous shocks to interest rates, this is probably as close as we're ever going to come as shocks that are uncorrelated with the observed variables in this dataset. I.e., it is plausible that we avoid the reverse causality problem, where $\\pi_t$, $u_t$, or $R_t$ causes $RR_t$. Meanwhile, we take the stance that $RR_t$ is allowed to cause $\\pi_t$, $u_t$, or $R_t$ to change. That seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Compare the IRFs for the Romer shocks from the two methods. How are they different, and why?\n",
    "Note: I can't get this package to give me the IRF to exogenous variables, which I know is the entire point. I tried another package, and it went even worse. Oh well. Based on my results, the outputs are remarkably similar. There are two main differences, as far as I can tell:\n",
    "\n",
    "1) The SVAR responses are smoother. \n",
    "2) The SVAR responses are much larger in magnitude.\n",
    "\n",
    "I think the smoothness is an artifact of the magnitude thing, and is not a deep result. The magnitude, however, is interesting _per se_. This tells me that the coefficients on lagged $RR_t$ are soaking up quite a bit of the variance in part (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Compare the VAR IRFs for the Romer shocks with the VAR IRFs for the SVAR shocks in Question (1d). How are they different, and why?\n",
    "Again, the magnitudes appear a bit bigger. But the biggest thing I see is that in response to a shock to $R_t$, there is a huge positive response of $\\pi_t$ in the Romer shocks models. This is, I think, the opposite of what I would expect if the Romer model were better at absorbing the endogeneity inherent in the forward-looking behavior of the Fed. Right? Raising interest rates should cause inflation to decrease, not increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Compare the Romer-Romer the identified monetary shocks in 2001Q3 and 2001Q4 with the SVAR identified monetary shocks. How are they similar / different?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the residuals (shocks) from the VAR model\n",
    "residuals_romer <- residuals(var_romer)\n",
    "\n",
    "# Convert residuals to a data frame for plotting\n",
    "residuals_romer_df <- data.frame(date = adjusted_dates, residuals_romer)\n",
    "\n",
    "# Rename the columns to match the variable names\n",
    "colnames(residuals_romer_df) <- c(\"date\", \"pi_shock\", \"u_shock\", \"R_shock\")\n",
    "\n",
    "# Set up a 3x1 plotting space\n",
    "par(mfrow = c(3, 1), mar = c(4, 4, 2, 1), bg = \"white\")  \n",
    "\n",
    "# Plot each shock time series\n",
    "plot(residuals_romer_df$date, residuals_romer_df$pi_shock, type = \"l\", col = \"red\", \n",
    "     xlab = \"\", ylab = \"Percentage Points\", main = \"Deviation in Inflation (pi) from VAR Prediction\")\n",
    "plot(residuals_romer_df$date, residuals_romer_df$R_shock, type = \"l\", col = \"blue\", \n",
    "     xlab = \"\", ylab = \"Percentage Points\", main = \"Deviation in Federal Funds Rate (R) from VAR Prediction\")\n",
    "plot(residuals_romer_df$date, residuals_romer_df$u_shock, type = \"l\", col = \"green\", \n",
    "     xlab = \"\", ylab = \"Percentage Points\", main = \"Deviation in Unemployment (u) from VAR Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the interest rate is actually goes up instead of down. This suggests to me that the response to September 11 by the Fed is actually being captured as a Romer shock — which suggests that they are responding to something other than observables in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
