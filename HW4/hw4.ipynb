{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 210C (Johannes) Homework 4 by Mikey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Productivity Shocks in the Three Equation Model\n",
    "\n",
    "### The log-linearized NK model boils down to three equations:\n",
    "$$\n",
    "\t\\begin{align*}\n",
    "\t\t\\hat{y}_t &=-\\sigma\\left[\\hat{i}_t-\\mathbb{E}_t\\left\\{\\hat{\\pi}_{t+1}\\right\\}\\right]+\\mathbb{E}_t\\left\\{\\hat{y}_{t+1}\\right\\} \\\\\n",
    "\t\t\\hat{\\pi}_t&=\\kappa \\left(\\hat{y}_t-\\hat{y}_t^{flex}\\right) +\\beta \\mathbb{E}_t \\left\\{\\hat{\\pi}_{t+1}\\right\\} \\\\\n",
    "\t\t\\hat{i}_t&=\\phi_\\pi\\hat{\\pi}_t+v_t \n",
    "\t\\end{align*}\n",
    "$$\n",
    "### with $\\hat{y}_t^{flex}=\\frac{1+\\varphi}{\\gamma+\\varphi}\\hat{a}_t$.\n",
    "\t\n",
    "### For this part assume that $v_t=0$ and that $\\hat{a}_t = \\rho_a \\hat{a}_{t-1} + \\epsilon_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Using the method of undetermined coefficients, solve for $\\hat{y}_t$ and $\\hat{\\pi}_t$ as a function of $\\hat{a}_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we make the following guesses:\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\hat{y}_t & = \\psi_{ya} \\hat{a}_t \\\\\n",
    "        \\hat{\\pi}_t & = \\psi_{\\pi a} \\hat{a}_t \\\\\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "Then we plug those to the first of the three given equations, noting that we're assuming $v_t=0$, so $\\hat{i}_t=\\phi_\\pi\\hat{\\pi}_t$. Further, assume that $\\mathbb{E}[\\epsilon_t] = 0$ for al $t$.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\psi_{ya} \\hat{a}_t &=-\\sigma\\left[\\phi_\\pi\\hat{\\pi}_t + v_t - \\mathbb{E}_t\\left\\{ \\psi_{\\pi a} \\hat{a}_{t+1} \\right\\}\\right]+\\mathbb{E}_t\\left\\{ \\psi_{ya} \\hat{a}_{t+1} \\right\\} \\\\\n",
    "        &=-\\sigma\\left[\\phi_\\pi\\psi_{\\pi a} \\hat{a}_t + 0 - \\mathbb{E}_t\\left\\{ \\psi_{\\pi a} \\left(\\rho_a \\hat{a}_t + \\epsilon_{t+1}\\right) \\right\\}\\right]+\\mathbb{E}_t\\left\\{ \\psi_{ya} \\left(\\rho_a \\hat{a}_t + \\epsilon_{t+1}\\right) \\right\\} \\\\\n",
    "        &=-\\sigma\\left[\\phi_\\pi\\psi_{\\pi a} \\hat{a}_t - \\psi_{\\pi a} \\rho_a \\hat{a}_t\\right]+ \\psi_{ya} \\rho_a \\hat{a}_t \\\\\n",
    "        \\psi_{ya} & = \\sigma\\left[\\psi_{\\pi a} \\rho_a -\\phi_\\pi\\psi_{\\pi a}\\right]+ \\psi_{ya} \\rho_a \\\\\n",
    "        \\psi_{ya} - \\psi_{ya} \\rho_a & = \\sigma \\psi_{\\pi a} \\left[\\rho_a -\\phi_\\pi\\right] \\\\\n",
    "        \\psi_{ya} & = \\frac{\\sigma \\psi_{\\pi a} \\left[\\rho_a -\\phi_\\pi\\right]}{1 - \\rho_a}\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "Now we follow the same procedure for the second equation.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\psi_{\\pi a} \\hat{a}_t&=\\kappa \\left(\\psi_{ya} \\hat{a}_t-\\frac{1+\\varphi}{\\gamma+\\varphi}\\hat{a}_t\\right) +\\beta \\mathbb{E}_t \\left\\{\\psi_{\\pi a} \\hat{a}_{t+1}\\right\\} \\\\\n",
    "        &=\\kappa \\left(\\psi_{ya} \\hat{a}_t-\\frac{1+\\varphi}{\\gamma+\\varphi}\\hat{a}_t\\right) +\\beta \\psi_{\\pi a} \\rho_a \\hat{a}_t \\\\\n",
    "        \\psi_{\\pi a} &=\\kappa \\left(\\psi_{ya} -\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) +\\beta \\psi_{\\pi a} \\rho_a\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "Now plug our first result into our second.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\psi_{\\pi a} &=\\kappa \\left(\\frac{\\sigma \\psi_{\\pi a} \\left[\\rho_a -\\phi_\\pi\\right]}{1 - \\rho_a} -\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) +\\beta \\psi_{\\pi a} \\rho_a \\\\\n",
    "        \\psi_{\\pi a} - \\frac{\\kappa \\sigma \\psi_{\\pi a} \\left[\\rho_a -\\phi_\\pi\\right]}{1 - \\rho_a} - \\beta \\psi_{\\pi a} \\rho_a &= -\\kappa \\frac{1+\\varphi}{\\gamma+\\varphi} \\\\\n",
    "        \\psi_{\\pi a} \\left(1 - \\frac{\\kappa \\sigma \\left[\\rho_a -\\phi_\\pi\\right]}{1 - \\rho_a} - \\beta \\rho_a \\right) &= -\\kappa \\frac{1+\\varphi}{\\gamma+\\varphi} \\\\\n",
    "        \\psi_{\\pi a} \\left( \\frac{(1- \\beta \\rho_a) (1 - \\rho_a) + \\kappa \\sigma \\left[\\phi_\\pi - \\rho_a \\right]}{1-\\rho_a} \\right) &= -\\kappa \\frac{1+\\varphi}{\\gamma+\\varphi} \\\\\n",
    "        \\psi_{\\pi a} &= -\\kappa \\left(\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) \\left( \\frac{1-\\rho_a}{(1- \\beta \\rho_a) (1 - \\rho_a) + \\kappa \\sigma \\left[\\phi_\\pi - \\rho_a \\right]} \\right)\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "And this back into our first.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\psi_{ya} & = \\left(\\frac{\\sigma \\left[\\rho_a -\\phi_\\pi\\right]}{1 - \\rho_a}\\right) \\left(-\\kappa \\left(\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) \\left( \\frac{1-\\rho_a}{(1- \\beta \\rho_a) (1 - \\rho_a) + \\kappa \\sigma \\left[\\phi_\\pi - \\rho_a \\right]} \\right)\\right) \\\\\n",
    "        & = -\\kappa \\sigma \\left[\\rho_a -\\phi_\\pi\\right] \\left(\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) \\left( \\frac{1}{(1- \\beta \\rho_a) (1 - \\rho_a) + \\kappa \\sigma \\left[\\phi_\\pi - \\rho_a \\right]} \\right)\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "For expositional purposes, define\n",
    "\n",
    "$$\n",
    "    \\psi_a = \\left( \\frac{1}{(1- \\beta \\rho_a) (1 - \\rho_a) + \\kappa \\sigma \\left[\\phi_\\pi - \\rho_a \\right]} \\right)\n",
    "$$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\psi_{\\pi a} &= -\\kappa \\left( 1-\\rho_a \\right) \\left(\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) \\psi_a \\\\\n",
    "        \\psi_{ya} & = -\\kappa \\sigma \\left( \\rho_a -\\phi_\\pi\\right) \\left(\\frac{1+\\varphi}{\\gamma+\\varphi}\\right) \\psi_a\n",
    "    \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Plot the impulse response function for $\\hat{y}_t$, $\\hat{y}_t^{flex}$, $\\hat{y}_t-\\hat{y}_t^{flex}$, $\\hat{i}_t$, $\\mathbb{E}_t[\\hat{r}_{t+1}]$, $\\hat{n}_{t}$, $\\hat{a}_t$ to a one unit shock to $\\hat{a}_t$. Use the following parameter values: $\\beta=0.99,\\sigma=1,\\kappa=0.1,\\rho_a=0.8,\\phi_\\pi=1.5, \\gamma=1$\n",
    "\n",
    "Notice that now $\\frac{1 + \\varphi}{\\gamma + \\varphi}$ reduces to 1, so our equations above simplify to \n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\psi_{\\pi a} &= -\\kappa \\left( 1-\\rho_a \\right) \\psi_a \\\\\n",
    "        \\psi_{ya} & = -\\kappa \\sigma \\left( \\rho_a -\\phi_\\pi\\right) \\psi_a\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "With these parameters (and noting that $\\sigma = 1/\\gamma = 1$) we now have most of these as linear functions of $\\hat{a}_t$. We don't yet have $\\mathbb{E}_t[\\hat{r}_{t+1}]$, but we can derive it. (This derivation should mostly be attributed to Shane.)\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        r_t & = \\frac{i_t}{\\pi_t} \\\\\n",
    "        \\ln(r_t) & = \\ln(i_t) - \\ln(\\pi_t) \\\\\n",
    "        \\ln(r_t) - \\ln(\\bar{r}) & = \\ln(i_t) - \\ln(\\pi_t) - \\left( \\ln(\\bar{i}) - \\ln(\\bar{\\pi}) \\right) \\\\\n",
    "        & = \\ln(i_t) - \\ln(\\bar{i}) -  \\left(\\ln(\\pi_t) - \\ln(\\bar{\\pi}) \\right) \\\\\n",
    "        \\hat{r}_t & = \\hat{i}_t - \\hat{\\pi}_t \\\\\n",
    "        \\hat{r}_{t+1} & = \\hat{i}_{t+1} - \\hat{\\pi}_{t+1} \\\\\n",
    "        \\mathbb{E}\\left[\\hat{r}_{t+1} \\right] & = \\mathbb{E}\\left[ \\hat{i}_{t+1} - \\hat{\\pi}_{t+1} \\right] \\\\\n",
    "        & = \\mathbb{E}\\left[ \\phi_\\pi\\hat{\\pi}_{t+1} - \\hat{\\pi}_{t+1} \\right] \\\\\n",
    "        & = \\mathbb{E}\\left[\\hat{\\pi}_{t+1} \\left( \\phi_\\pi - 1 \\right) \\right] \\\\\n",
    "        & = \\left( \\phi_\\pi - 1 \\right) \\mathbb{E}\\left[\\hat{\\pi}_{t+1} \\right] \\\\\n",
    "        & = \\left( \\phi_\\pi - 1 \\right) \\left(\\psi_{\\pi a} a_t - \\kappa\\left(\\psi_{ya} a_t - \\frac{1 + \\varphi}{\\gamma + \\varphi} a_t\\right) \\right) \\\\\n",
    "        & = \\left( \\phi_\\pi - 1 \\right) \\left(\\psi_{\\pi a} a_t - \\kappa\\left(\\psi_{ya} a_t - a_t\\right) \\right) \\\\\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "We are also missing labor demand, but we know that's just $\\hat{n}_t = \\hat{y}_t - \\hat{a}_t$. Now, for reference, let's write down all the variables for which we're asked to do an impulse response.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\hat{y}_t & = \\psi_{ya} \\hat{a}_t \\\\\n",
    "        \\hat{\\pi}_t & = \\psi_{\\pi a} \\hat{a}_t \\\\\n",
    "        \\hat{y}_t^{flex} & = \\hat{a}_t \\\\\n",
    "        \\hat{y}_t - \\hat{y}_t^{flex} & = \\hat{a}_t \\left(\\psi_{ya} - 1\\right) \\\\\n",
    "        \\hat{i}_t & = \\phi_\\pi \\psi_{\\pi a} \\hat{a}_t \\\\\n",
    "        \\mathbb{E}\\left[\\hat{r}_{t+1} \\right] & = \\left( \\phi_\\pi - 1 \\right) \\left(\\psi_{\\pi a} - \\kappa \\psi_{ya} - \\kappa \\right) a_t \\\\\n",
    "        \\hat{n}_t & = \\psi_{ya} \\hat{a}_t - \\hat{a}_t \\\\\n",
    "        \\hat{a}_t & = \\rho_a \\hat{a}_{t-1}\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "OK, now time to set up the python code for the impulse repsonse functions, which I copy almost exactly from Bridget. We start by loading the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define all the parameters as given in part (b) or as calculated in part (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "beta = 0.99\n",
    "sigma = 1\n",
    "kappa = 0.1\n",
    "rho = 0.8\n",
    "phi = 1.5\n",
    "gamma = 1\n",
    "psi_a = 1 / ((1 - beta * rho) * (1 - rho) + kappa * sigma * (phi - rho))\n",
    "psi_pi = - kappa * (1 - rho) * psi_a\n",
    "psi_y = - kappa * sigma * (rho - phi) * psi_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the variables. They consist of empty lists in which to store the results of the impulse response function, e.g., $\\left\\{\\hat{y}_t \\right\\}$, $\\left\\{\\hat{\\pi}_t \\right\\}$, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "y = []\n",
    "pi = []\n",
    "yflex = []\n",
    "y_yflex = []\n",
    "i = []\n",
    "er = []\n",
    "n = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pick a value for the productivity shock $a_0$ and then define a variable $a_{t-1}$ that starts at $a_0$. The intuition for why we need this special step for productivity is that when we calculate $a_t$, we need to know $a_{t-1}$ — whereas all the other variables are “memoryless,” i.e., they can be calculated using only parameters and current values of variables. Then we create a list for $\\left\\{\\hat{a}_t \\right\\}$, which, unlike the other variables, we do not leave empty; rather, it begins with a_0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial value\n",
    "a0 = 1\n",
    "a_t1 = a0\n",
    "a = [a0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate all the variables according to the equations we solved for above, storing the results in the lists we just created. Then we iterate this loop 20 times, calculating and then storing the results for $t = 1, 2, \\dots, 20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(20):\n",
    "    a_t = rho*a_t1\n",
    "    a.append(a_t)\n",
    "    y_t = psi_y*a_t\n",
    "    y.append(y_t)\n",
    "    pi_t = psi_pi*a_t\n",
    "    pi.append(pi_t)\n",
    "    yflex_t = a_t\n",
    "    yflex.append(yflex_t)\n",
    "    y_yflex_t = y_t-yflex_t\n",
    "    y_yflex.append(y_yflex_t)\n",
    "    i_t = phi*psi_pi*a_t\n",
    "    i.append(i_t)\n",
    "    er_t1 = (phi - 1) * (psi_pi - kappa * psi_y - kappa) * a_t\n",
    "    er.append(er_t1)\n",
    "    n_t = y_t - a_t\n",
    "    n.append(n_t)\n",
    "    a_t1 = a_t\n",
    "    i_t1 = i_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the results for the impulse response functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, one_b = plt.subplots(4, 2, figsize=(12, 20))\n",
    "one_b[0, 0].plot(a, label='a')\n",
    "one_b[0, 0].set_title('Productivity Shock')\n",
    "one_b[0, 1].plot(y, label='y')\n",
    "one_b[0, 1].set_title('Output')\n",
    "one_b[1, 0].plot(pi, label='pi')\n",
    "one_b[1, 0].set_title('Inflation')\n",
    "one_b[1, 1].plot(yflex, label='yflex')\n",
    "one_b[1, 1].set_title('Output under Flexible Prices')\n",
    "one_b[2, 0].plot(y_yflex, label='y_yflex')\n",
    "one_b[2, 0].set_title('Output Gap')\n",
    "one_b[2, 1].plot(i, label='i')\n",
    "one_b[2, 1].set_title('Nominal Interest Rate')\n",
    "one_b[3, 0].plot(er, label='er')\n",
    "one_b[3, 0].set_title('Expected Real Intrest Rate')\n",
    "one_b[3, 1].plot(n, label='n')\n",
    "one_b[3, 1].set_title('Employment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Intuitively explain your results.\n",
    "\n",
    "**Productivity**: The positive productivity shock dissipates over time because it's an AR1 process and the autocorrelation coefficient is less than 1. This shock causes the following responses...\n",
    "\n",
    "**Output**: A positive shock to output, which makes sense because the firms need set MRPL equal to zero. Equivalently, a positive shock to $a_t$ is a negative shock to inflation (see below), which means firms are lowering their prices, which results in more consumption demand and therefore more output.\n",
    "\n",
    "**Inflation**: A negative shock to inflation, which makes sense because in this model, inflation is proportional to the output gap, which, as we are soon to see, is negative here.\n",
    "\n",
    "**Output under flexible prices**: A positive shock to $\\hat{y}_t^{flex}$ according to the same logic behind the output result.\n",
    "\n",
    "**Output gap**: A negative shock to the output gap because in this sticky prices model, some fraction of firms in any given period is unable to adjust its prices in response to the shock. Firm with un-stuck prices ajdust down, making the firms with stuck prices look relatively expensive, cutting into their demand. While some consumption is reallocated from stuck firms to unstuck firms, it's not totally net neutral: the geometric average of demand across all the goods is lower than it would be if all firms were unstuck. In general, the output gap should be inversly proportional to the gap between the real interest rate and the \n",
    "\n",
    "**Nominal interest rate**: A negative shock to nominal interest rate because the central bank follows the Taylor Rule and sets interest rates proportional to inflation.\n",
    "\n",
    "**Expected real interest rate**: A negative shock to real interest rate because prices don't completely adjust; rather, they're expected to slowly return to the steady state, so they cannot entirely offset the lower nominal interest rates.\n",
    "\n",
    "**Employement** A negative shock to employement because consumers equate marginal utility of consumption to marginal utility of leisure, and productivity went up, so if labor were held constant, output would be much higher, conumption would be much higher, and marginal utility of consumption would be lower; then households would want to increase leisure and decrease labor — i.e., the income effect loses out to the substitution effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Use the Jupyter notebook \"newkeynesianlinear.ipynb\" to check that your plots in (b) are correct.\n",
    "\n",
    "We need to make a few changes to Johannes's code to change it from a shock to $v_t$ to a shock to $a_t$. I'll copy (a simplified version of) that code here and comment the changes (for which I entirely credit Beatrice).\n",
    "\n",
    "*Note: you might need to install some packages.*\n",
    "\n",
    "```\n",
    "pip install sequence_jacobian\n",
    "pip install numba\n",
    "pip install graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_jacobian import simple, create_model\n",
    "\n",
    "# This is a newly defined thing. \n",
    "@simple\n",
    "def flex(a):\n",
    "    yflex = a \n",
    "    return yflex\n",
    "\n",
    "@simple\n",
    "def nkpc(pi, yflex, beta, kappa):\n",
    "    y = yflex + 1 / kappa * (pi - beta * pi(+1))\n",
    "    return y\n",
    "\n",
    "@simple\n",
    "def central_bank(pi, v, phi_pi):\n",
    "    i = phi_pi * pi + v\n",
    "    return i\n",
    "\n",
    "@simple\n",
    "def mkt_clearing(y, i, pi, gamma):\n",
    "    euler = gamma * y + i - pi(+1) - gamma * y(+1)\n",
    "    r = i - pi(+1)\n",
    "    c = y\n",
    "    return euler, r, c\n",
    "\n",
    "# We now need to include the flex thing.    \n",
    "nk = create_model([flex, nkpc, central_bank, mkt_clearing], name=\"NK\")\n",
    "\n",
    "# Now we have `a' as an input instead of `yflex'.\n",
    "unknowns = ['pi']\n",
    "targets = ['euler']\n",
    "inputs = ['a', 'v']\n",
    "\n",
    "gamma = 1\n",
    "beta = 0.99\n",
    "phi_pi = 1.5\n",
    "kappa = 0.1\n",
    "\n",
    "# When we calculate the steady state values, we specify `a' instead of `yflex'.\n",
    "calibration = {'a': 0, 'v': 0, 'y': 0, 'c': 0, 'r': 0, 'i': 0, 'gamma': gamma, 'beta': beta, 'phi_pi': phi_pi, 'kappa': kappa}\n",
    "\n",
    "unknowns_ss = {'pi': 0}\n",
    "targets_ss = { \"euler\": 0}\n",
    "\n",
    "ss = nk.solve_steady_state(calibration, unknowns_ss, targets_ss, solver=\"broyden_custom\")\n",
    "\n",
    "G = nk.solve_jacobian(ss, unknowns, targets, inputs, T=300)\n",
    "\n",
    "calibration2 = calibration.copy()\n",
    "calibration2['kappa'] = 10\n",
    "\n",
    "ss2 = nk.solve_steady_state(calibration2, unknowns_ss, targets_ss, solver=\"broyden_custom\")\n",
    "\n",
    "G2 = nk.solve_jacobian(ss2, unknowns, targets, inputs, T=300)\n",
    "\n",
    "# Change `dv' to `da'.\n",
    "T, Tplot, impact, rho, news = 300, 20, 0.01, 0.8, 10\n",
    "da = np.empty((T, 1))\n",
    "da[:, 0] = impact * rho**np.arange(T)\n",
    "\n",
    "# Change `v' to `a' and `dv' to `da'.\n",
    "plotset = ['a', 'r', 'i', 'pi', 'y', 'c']\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i, var in enumerate(plotset):\n",
    "    if var == 'a':\n",
    "        irf1 = da[:Tplot]\n",
    "        irf2 = da[:Tplot]\n",
    "    else:\n",
    "        irf1 = 100 * (G[var]['a'] @ da)[:Tplot]\n",
    "        irf2 = 100 * (G2[var]['a'] @ da)[:Tplot]\n",
    "    axi = ax[i // 3, i % 3]\n",
    "\n",
    "    # We got rid of label=\"kappa=0.1\" because there's only one kappa now.\n",
    "    axi.plot(irf1)\n",
    "    \n",
    "    # We dropped the following line because we don't care about kappa = 10.\n",
    "    # axi.plot(irf2, label=\"kappa=10\")\n",
    "    \n",
    "    axi.set_title(f\"{var}\")\n",
    "    axi.xlabel = \"quarters\"\n",
    "    axi.ylabel = \"% deviation\"\n",
    "    \n",
    "    # We don't have a legend anymore.\n",
    "    # axi.legend()\n",
    "\n",
    "# plt.savefig(\"nklinearirf_2.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks identical to my IRFs. Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Non-linear NK model in Jupyter\n",
    "### Implement the standard new Keynesian model in Jupyter. We will write all conditions recursively and let the Sequence-Space Jacobian (SSJ) routines do the differentiation for us. Note that the first order conditions for firms and households are exactly as we have written in the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (a) The real reset price equation for the firm is,\n",
    "$$\n",
    "    \\begin{align*}\n",
    "\t\tp_t^*\\equiv\\frac{P_t^*}{P_{t}} &=  (1+\\mu)E_t\\left\\{\\sum_{s=0}^{\\infty}\\frac{\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s}/P_t)^{\\epsilon-1}}{\\sum_{k=0}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_t)^{\\epsilon-1}}\\frac{W_{t+s}/P_{t}}{A_{t+s}}\\right\\}\n",
    "\t\\end{align*}\n",
    "$$\n",
    "### Explain why this expression is not recursive.\n",
    "I feel like the problem is that we can't separate each individual element of the sum, which is why we need to write the numerator and denominator as having two different indices. I.e., we need to compute the sum on the top, and then separately compute the sum on the bottom. The difference between the two is that each term in the top is being scaled by the appropriate marginal cost–looking thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) We next show that we can write $B_t=E_t(F_{1t}/F_{2t})$ (this is a typo: $B_t$ should be $p_t^*$), where both $F_{1t},F_{2t}$ are recursive. First, show that the denominator can be recursively written as,\n",
    "$$\n",
    "\t\\begin{align*}\n",
    "\t\tF_{2t}&\\equiv \\sum_{k=0}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_t)^{\\epsilon-1} \\\\\n",
    "\t\t&=Y_t+\\theta\\Pi_{t+1}^{\\epsilon-1}\\Lambda_{t,t+1}F_{2,t+1}\n",
    "\t\\end{align*}\n",
    "$$\n",
    "### noting that $\\Lambda_{t,t+k}=\\Lambda_{t,t+1}\\Lambda_{t+1,t+k}$ for all $k\\ge 1$.\n",
    "First we break out the $t=0$ term. I don't entirely understand what this stochastic discount factor thing is, but surely we don't discount today from the perspective of today, so I would wager a bet that $\\Lambda_{t,t} = 1$.\n",
    "$$\n",
    "    \\begin{align*}\n",
    "\t\tF_{2t} & = \\sum_{k=0}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_t)^{\\epsilon-1} \\\\\n",
    "        &=\\theta^0 \\Lambda_{t,t} Y_t (P_{t}/P_t)^{\\epsilon-1} +\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_t)^{\\epsilon-1} \\\\\n",
    "        &=(1) (1) (Y_t) (1)^{\\epsilon-1} +\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_t)^{\\epsilon-1} \\\\\n",
    "\t\t&=Y_t+\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_t)^{\\epsilon-1}\n",
    "    \\end{align*}\n",
    "$$\n",
    "Now the goal is to make the second term here look exactly like what we started with, but with $t+1$ in the place of all the $t$'s. Our first troublemaker is $P_t$, which we can pull outside the sum because it's not indexed by $k$. But then we need to get $P_{t+1}$ in there, so we'll multiply and divide by it, and then move what we don't need outside the sum (since $P_{t+1}$ also doesn't depend on $k$).\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        &=Y_t+\\left(\\frac{1}{P_t}\\right)^{\\epsilon-1}\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k})^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\left(\\frac{1}{P_t}\\right)^{\\epsilon-1}\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k})^{\\epsilon-1} \\left(\\frac{P_{t+1}}{P_{t+1}}\\right)^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1}\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k}Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "    \\end{align*}\n",
    "$$\n",
    "The next troublemaker is $\\Lambda_{t,t+k}$. Rearranging the handy note, we see that $\\Lambda_{t+1,t+k} = \\Lambda_{t,t+k} / \\Lambda_{t,t+1}$. So if we multiply and divide by $\\Lambda_{t,t+1}$ (which also doesn't depend on $k$), that'll help.\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        &=Y_t+\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1}\\sum_{k=1}^{\\infty}\\theta^k\\Lambda_{t,t+k} \\left( \\frac{\\Lambda_{t,t+1}}{\\Lambda_{t,t+1}} \\right)Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1} \\Lambda_{t,t+1} \\sum_{k=1}^{\\infty}\\theta^k \\left( \\frac{\\Lambda_{t,t+k}}{\\Lambda_{t,t+1}} \\right)Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1} \\Lambda_{t,t+1} \\sum_{k=1}^{\\infty}\\theta^k \\Lambda_{t+1,t+k} Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "    \\end{align*}\n",
    "$$\n",
    "The last thing we need to do is pull out a $\\theta$ because of a reason I don't fully understand, but I guess we want the first term in this new sum not to be discounted by the probability of being stuck. Anyway, once we do that, the sum looks exactly like $F_2$ iterated forward one period. Then we note that $\\frac{P_{t+1}}{P_t}$ is just inflation (for which, for some reason, we're using a capital $\\Pi$ now) and we're done.\n",
    "$$\n",
    "    \\begin{align*}\n",
    "\t\t&=Y_t+\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1} \\Lambda_{t,t+1} \\sum_{k=1}^{\\infty}\\theta^k \\Lambda_{t+1,t+k} Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1} \\Lambda_{t,t+1} \\sum_{k=1}^{\\infty}(\\theta)\\theta^{k-1} \\Lambda_{t+1,t+k} Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\theta\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1} \\Lambda_{t,t+1} \\sum_{k=1}^{\\infty}\\theta^{k-1} \\Lambda_{t+1,t+k} Y_{t+k}(P_{t+k}/P_{t+1})^{\\epsilon-1} \\\\\n",
    "        &=Y_t+\\theta\\left(\\frac{P_{t+1}}{P_t}\\right)^{\\epsilon-1} \\Lambda_{t,t+1} F_{2, t+1} \\\\\n",
    "\t\t&=Y_t+\\theta\\Pi_{t+1}^{\\epsilon-1}\\Lambda_{t,t+1}F_{2,t+1}\n",
    "\t\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Second, show that the numerator can be recursively written as,\n",
    "$$\n",
    "\t\\begin{align*}\n",
    "\t\tF_{1t}&\\equiv (1+\\mu)\\sum_{s=0}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s}/P_t)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}}  \\\\\n",
    "\t\t&=(1+\\mu)Y_t\\frac{W_{t}/P_{t}}{A_{t}}+\\theta\\Pi_{t+1}^{\\epsilon}\\Lambda_{t,t+k}F_{1,t+1}\n",
    "\t\\end{align*}\n",
    "$$\n",
    "### noting that $\\Lambda_{t,t+k}\\Lambda_{t,t+1}\\Lambda_{t+1,t+k}$ for all $k\\ge 1$.\n",
    "\n",
    "This is the same procedure, so I'll omit the commentary. The only difference is that we have to convert a $P-t$ into a $P_{t+1}$ in the real wage, so an extra $P_{t+1}/P_t$ gets pulled out front.\n",
    "\n",
    "$$\n",
    "\t\\begin{align*}\n",
    "\t\tF_{1t} & = (1+\\mu)\\sum_{s=0}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s}/P_t)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) \\theta^0 \\Lambda_{t,t} Y_t \\left(\\frac{P_t}{P_t}\\right)^{\\epsilon -1} \\left(\\frac{W_t/P_t}{A_t}\\right) + (1+\\mu)\\sum_{s=1}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s}/P_t)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + (1+\\mu)\\sum_{s=1}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s}/P_t)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\left(\\frac{1}{P_t}\\right)^{\\epsilon-1}(1+\\mu)\\sum_{s=1}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s})^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\left(\\frac{1}{P_t}\\right)^{\\epsilon-1}(1+\\mu)\\sum_{s=1}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s}(P_{t+s})^{\\epsilon-1} \\left(\\frac{P_{t+1}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\Pi_{t+1}^{\\epsilon-1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s} \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\Pi_{t+1}^{\\epsilon-1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^s\\Lambda_{t,t+s}Y_{t+s} \\left(\\frac{\\Lambda_{t,t+1}}{\\Lambda_{t,t+1}}\\right) \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\Pi_{t+1}^{\\epsilon-1}\\Lambda_{t,t+1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^sY_{t+s} \\left(\\frac{\\Lambda_{t,t+s}}{\\Lambda_{t,t+1}}\\right) \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\Pi_{t+1}^{\\epsilon-1}\\Lambda_{t,t+1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^sY_{t+s} \\Lambda_{t+1,t+s} \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\theta \\Pi_{t+1}^{\\epsilon-1}\\Lambda_{t,t+1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^{s-1}Y_{t+s} \\Lambda_{t+1,t+s} \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\theta \\Pi_{t+1}^{\\epsilon-1}\\Lambda_{t,t+1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^{s-1}Y_{t+s} \\Lambda_{t+1,t+s} \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t}}{A_{t+s}} \\left(\\frac{P_{t+1}}{P_{t+1}}\\right) \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\theta \\Pi_{t+1}^{\\epsilon-1} \\left(\\frac{P_{t+1}}{P_{t}}\\right) \\Lambda_{t,t+1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^{s-1}Y_{t+s} \\Lambda_{t+1,t+s} \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t+1}}{A_{t+s}}  \\\\\n",
    "        & = (1 + \\mu) Y_t \\left(\\frac{W_t/P_t}{A_t}\\right) + \\theta \\Pi_{t+1}^{\\epsilon} \\Lambda_{t,t+1} (1+\\mu) \\sum_{s=1}^{\\infty}\\theta^{s-1}Y_{t+s} \\Lambda_{t+1,t+s} \\left(\\frac{P_{t+s}}{P_{t+1}}\\right)^{\\epsilon-1}\\frac{W_{t+s}/P_{t+1}}{A_{t+s}}  \\\\\n",
    "\t\t&=(1+\\mu)Y_t\\frac{W_{t}/P_{t}}{A_{t}}+\\theta\\Pi_{t+1}^{\\epsilon}\\Lambda_{t,t+k}F_{1,t+1}\n",
    "\t\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Show that (gross) inflation can implicitly be written as\n",
    "$$\n",
    "\t\\begin{align*}\n",
    "\t\t1&=\\theta \\Pi_{t}^{\\epsilon-1} + (1-\\theta) p_{t}^{*1-\\epsilon}\n",
    "\t\\end{align*}\n",
    "$$\n",
    "\n",
    "Start with the definition of the aggregate price level $P_t$, and then divide through by $P_t$.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "\t\tP_t & =\\left[\\theta P_{t-1}^{1-\\epsilon} + (1-\\theta) P_{t}^{*1-\\epsilon}\\right]^{\\frac{1}{1-\\epsilon}} \\\\\n",
    "        {P_t}^{1-\\epsilon} & =\\left[\\theta P_{t-1}^{1-\\epsilon} + (1-\\theta) P_{t}^{*1-\\epsilon}\\right] \\\\\n",
    "        1 & =\\theta \\left(\\frac{P_{t-1}^{1-\\epsilon}}{{P_t}^{1-\\epsilon}}\\right) + (1-\\theta) \\left(\\frac{P_{t}^{*1-\\epsilon}}{{P_t}^{1-\\epsilon}}\\right)  \\\\\n",
    "        1 & =\\theta \\left(\\frac{P_{t-1}}{P_t}\\right)^{1-\\epsilon} + (1-\\theta) \\left(\\frac{P_{t}^*}{{P_t}}\\right)^{1-\\epsilon}  \\\\\n",
    "        1 & =\\theta \\left(\\frac{P_{t}}{P_{t-1}}\\right)^{\\epsilon-1} + (1-\\theta) \\left(\\frac{P_{t}^*}{{P_t}}\\right)^{1-\\epsilon} \\\\\n",
    "\t\t1 & = \\theta \\Pi_{t}^{\\epsilon-1} + (1-\\theta) {p_{t}^*}^{1-\\epsilon}\n",
    "\t\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Explain intuitively how when $p_t^*>1$, then $\\Pi_t>1$.\n",
    "Mechanically, if the real reset price $p_t^* = P_t^* / P_t > 1$, then $P_t^* > P_t$. This means that the unstuck firms are above the aggregate price level, so the unstuck firm have adjusted up, the stuck firms are stuck at some lower level, and the aggregate is somewhere in the middle. The stuck firms are actually stuck at whatever they were at last period, which (on average) is $P_{t-1}$. This means that $P_t > P_{t-1}$, so $\\Pi_t = P_t /P_{t-1} > 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Implement the non-linear NK using your recursive equations in Python using the Sequence Space Jacobian toolbox. For now, ignore the dispersion of labor in production and write the aggregate production function as $Y_t=A_tN_t$. Use the following parameters: $\\beta=0.99,\\gamma=1,\\varphi=1,\\chi=1,\\epsilon=10,\\rho_a=0.8,\\phi_\\pi=1.5,\\phi_y=0$ where $A_t=(A_{t-1})^{\\rho_a}e^{\\epsilon_t^a}$. Productivity is the only shock. Price stickiness is specified below.\n",
    "\n",
    "*This is entirely stolen from Bridget, who I believe had help from Jack and Beatrice.*\n",
    "\n",
    "First, we import packages. These are the same as used in previous problems, so I don't know if it's necessary, but better safe than sorry. It's worth saying a bit about this line:\n",
    "```\n",
    "from sequence_jacobian import simple, create_model, solved\n",
    "```\n",
    "In the Sequence Space Jacobian package, there are a few special functions defined, and these are the ones we'll need: ```simple```, ```create_model```, and ```solved```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sequence_jacobian import simple, create_model, solved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plug in the parameters as defined in the prompt. This is pretty self explanatory, except for what's going on with theta: first we define ```theta_``` as a list of the values given in the prompt. Then we define ```theta``` to be the first (which, in python, is the 0-th) item in that list — for now, anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set Parameters\n",
    "beta = 0.99\n",
    "gamma = 1\n",
    "varphi = 1\n",
    "chi = 1\n",
    "epsilon = 10\n",
    "rho_a = 0.8\n",
    "phi_pi = 1.5\n",
    "phi_y = 0 \n",
    "mu = 1/(epsilon-1)\n",
    "theta_ = [0.0001, 0.25, 0.5, 0.75, 0.9999]\n",
    "\n",
    "# Take the first element of the list\n",
    "theta = theta_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the blocks. Let's look at the first block in detail.\n",
    "\n",
    "The first thing we need is the decorator ```@simple``` tells the Sequence Space Jacobian package that this thing is a simple block and should be treated as such — what exactly that entails, I have no idea. But apparently, simple blocks are used to represent explicit aggregate equilibrium conditions. Anyway, what we do is define a new function called ```hh``` and specify that it takes some specific variables as inputs. Then we calculate a few variables\n",
    "\n",
    "1.  ```wp```: Real wage $W_t/P_t$\n",
    "2.  ```sdf```: Stochastic discount factor $\\Lambda_t$\n",
    "3. ```r```: Real interest rate $R_t$.\n",
    "\n",
    "Finally, we specify that this ```hh``` function, if fed the appripriate inputs, should ouput values for those three variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define household block\n",
    "@simple\n",
    "def hh(c, n, varphi, gamma, beta, chi):\n",
    "    wp = chi*(n**varphi)/(c**(-gamma))\n",
    "    sdf = beta*(c**(-gamma))/(c(-1)**(-gamma))\n",
    "    r = 1/(beta*(c**(-gamma))/(c(-1)**(-gamma)))\n",
    "    return wp, sdf, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a similar but more complicated thing for the firm block. This is a ```solved``` block, which means it is being used for implicit aggregate equilibrium conditions. In other words, whereas in the household block we could just straight up calculate each of the outputs as function of some combination of the inputs, here we have some variables that depend on other variables *within this block*. For example ```gap``` depends on ```y``` and ```yflex```, which we also calculate in the firm block.\n",
    "\n",
    "Furthermore, ```solved``` blocks require us to specify two new objects:\n",
    "1. ```unknowns```: variables that the block is supposed to solve for, but may be more complicated that just plugging in some numbers, i.e., they must satisfy some system of equations. These each unknown also must include an “initial guess.”\n",
    "2.  ```targets```: equations that must be satisfied. \n",
    "\n",
    "Also showing up in this block are lagged/lead variables, e.g., ```pi``` is $\\Pi_t$ and ```pi(+1)``` is $\\Pi_{t+1}$. Unlike in simple blocks, in solved blocks you're allowed to refer to the lead/lag of a variable that was created *within this block*, which we do here with ```f1```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define firm block\n",
    "@solved(unknowns={'f1': (1+mu)*chi/(1-theta*beta), 'f2': 1/(1-theta*beta)}, targets=['F1', 'F2'], solver=\"broyden_custom\")\n",
    "def firm(sdf, wp, a, pi, n, mu, theta, epsilon, f1, f2):    \n",
    "    y = a*n\n",
    "    yflex = a**((1+varphi)/(gamma+varphi))\n",
    "    gap = y-yflex\n",
    "    F1 = (1 + mu) * (a * n) * (wp / a) + theta * (pi(+1) ** epsilon) * sdf(+1) * f1(+1) - f1\n",
    "    F2 = (a * n) + theta * (pi(+1) ** (epsilon - 1)) * sdf(+1) * f2(+1) - f2\n",
    "    return F1, F2, y, gap, yflex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few more simple blocks, which are fairly self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define second firm block\n",
    "@simple\n",
    "def firm2(f1, f2):\n",
    "    pstar = f1 / f2\n",
    "    return pstar\n",
    "\n",
    "# Define central bank block\n",
    "@simple\n",
    "def central_bank(pi, v, phi_pi, beta):\n",
    "    q = (1 / beta) * (pi ** phi_pi) * v\n",
    "    return q\n",
    "\n",
    "# Define market clearing block\n",
    "@simple\n",
    "def mkt_clearing(y, c, pstar, q, r, pi, theta, epsilon):\n",
    "    output = y - c\n",
    "    inflation  = theta*(pi**(epsilon-1))+(1-theta)*(pstar**(1-epsilon)) - 1\n",
    "    fisher = r(+1) - q/pi(+1)\n",
    "    return fisher, output, inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nk = create_model([hh, firm, firm2, central_bank, mkt_clearing], name=\"NK\")\n",
    "\n",
    "print(nk)\n",
    "print(f\"Blocks: {nk.blocks}\")\n",
    "\n",
    "# steady state values\n",
    "calibration = {'v': 1.0, 'a': 1.0, 'y': 1.0, 'r': 1.0/beta, 'sdf': beta, 'wp': chi, 'q': 1.0 / beta, 'gamma': gamma, 'beta': beta, 'phi_pi': phi_pi, 'theta': theta, 'varphi': varphi, 'chi': chi, 'mu': mu, 'epsilon': epsilon}\n",
    "\n",
    "# solve for steady state (we know it, but running this routine helps us check for mistakes)\n",
    "unknowns_ss = {'n': 1.0, 'c': 1.0, 'pi': 1.0}\n",
    "targets_ss = {'fisher': 0.0, 'output': 0.0, 'inflation': 0.0}\n",
    "\n",
    "ss = nk.solve_steady_state(calibration, unknowns_ss, targets_ss, solver=\"broyden_custom\")\n",
    "\n",
    "# Print steady-state results\n",
    "print(\"Steady-state values:\")\n",
    "for key, value in ss.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Check that the residuals are close to zero\n",
    "fisher_residual = ss['fisher']\n",
    "output_residual = ss['output']\n",
    "inflation_residual = ss['inflation']\n",
    "print(f\"fisher residual: {fisher_residual}\")\n",
    "print(f\"output residual: {output_residual}\")\n",
    "print(f\"inflation residual: {inflation_residual}\")\n",
    "\n",
    "unknowns = ['n', 'c', 'pi']\n",
    "targets = ['fisher', 'output', 'inflation']\n",
    "inputs = ['a', 'v']\n",
    "\n",
    "G = nk.solve_jacobian(ss, unknowns, targets, inputs, T=300)\n",
    "\n",
    "print(G)\n",
    "\n",
    "calibration_copies = {}\n",
    "# change calibration\n",
    "for i in range(1,len(theta_)):\n",
    "    calibration_i = calibration.copy()\n",
    "    calibration_i['theta'] = theta_[i]\n",
    "\n",
    "    # calculate new steady state\n",
    "    ss_i = nk.solve_steady_state(calibration_i, unknowns_ss, targets_ss, solver=\"broyden_custom\")\n",
    "\n",
    "    # calculate new Jacobian\n",
    "    G_i = nk.solve_jacobian(ss_i, unknowns, targets, inputs, T=300)\n",
    "\n",
    "    calibration_copies[f'G_{i}'] = G_i\n",
    "\n",
    "T, Tplot, impact, rho_a = 300, 20, 0.01, rho_a\n",
    "da = np.empty((T, 1))\n",
    "da[:, 0] = impact * rho_a**np.arange(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Compute IRFs for $\\theta\\in\\{0.0001,0.25,0.5,0.75,0.9999\\}$ using a first order approximation to your non-linear equations.\n",
    "\t\n",
    "### Report the IRFs for consumption, the output gap, the level of output, employment, inflation, the mark-up, the nominal interest rate, and the ex-ante real interest rate. Your graph for each variable should contain all cases for $\\theta$, appropriately labelled. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot responses\n",
    "plotset = ['a','c', 'gap', 'y','n','pi','q','r']\n",
    "fig, ax = plt.subplots(4, 2, figsize=(12, 20))\n",
    "for i, var in enumerate(plotset):\n",
    "    if var == 'a':\n",
    "        irf1 = da[:Tplot]\n",
    "        irf2 = da[:Tplot]\n",
    "        irf3 = da[:Tplot]\n",
    "        irf4 = da[:Tplot]\n",
    "        irf5 = da[:Tplot]\n",
    "    elif var == 'r':\n",
    "        irf1 = 100 * (G[var]['a'] @ da)[1:Tplot]\n",
    "        irf2 = 100 * (calibration_copies['G_1'][var]['a'] @ da)[1:Tplot]\n",
    "        irf3 = 100 * (calibration_copies['G_2'][var]['a'] @ da)[1:Tplot]\n",
    "        irf4 = 100 * (calibration_copies['G_3'][var]['a'] @ da)[1:Tplot]\n",
    "        irf5 = 100 * (calibration_copies['G_4'][var]['a'] @ da)[1:Tplot]\n",
    "    else:\n",
    "        irf1 = 100 * (G[var]['a'] @ da)[:Tplot]\n",
    "        irf2 = 100 * (calibration_copies['G_1'][var]['a'] @ da)[:Tplot]\n",
    "        irf3 = 100 * (calibration_copies['G_2'][var]['a'] @ da)[:Tplot]\n",
    "        irf4 = 100 * (calibration_copies['G_3'][var]['a'] @ da)[:Tplot]\n",
    "        irf5 = 100 * (calibration_copies['G_4'][var]['a'] @ da)[:Tplot]\n",
    "    axi = ax[i // 2, i % 2]\n",
    "    axi.plot(irf1, label=f\"theta={theta_[0]}\")\n",
    "    axi.plot(irf2, label=f\"theta={theta_[1]}\")\n",
    "    axi.plot(irf3, label=f\"theta={theta_[2]}\")\n",
    "    axi.plot(irf4, label=f\"theta={theta_[3]}\")\n",
    "    axi.plot(irf5, label=f\"theta={theta_[4]}\")\n",
    "    axi.set_title(f\"{var}\")\n",
    "    axi.xlabel = \"quarters\"\n",
    "    axi.ylabel = \"% deviation\"\n",
    "    axi.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) Intuitively explain how the impulse response functions depend on the value of $\\theta$.\n",
    "Remember that $\\theta$ is the probability with which a firm is forbidden to adjust their prices in a given period and therefore are stuck with their prices from the previous period; in the aggreagte, the law of large numbers tells us that $\\theta$ can also be thought of as the fraction of stuck firms. To get a handle on the intuition, first consider the extremes.\n",
    "\n",
    "$\\theta = 0.0001$: this is almost indistinguishable from the case of fully flexible prices, where all firms are allowed to instantly adjust optimally. Remember, given the assumptions, $\\hat{y}_t^{flex} = \\hat{a}_t$, so in this case output should move almost one-for-one with productivity. Reassuringly, that's what we see, and the output gap is virtually zero. If $\\hat{y}_t = \\hat{a}_t$ then, mechanically, labor doesn't move: $\\hat{n}_t = \\hat{y}_t - \\hat{a}_t = \\hat{a}_t - \\hat{a}_t = 0$ (remember, these are log linearized, so $\\hat{n}_t = 0$ means zero deviation from steady state). Now let's look at the money stuff. Prices adjust down in response to the increased output, so inflation is sharply negative. The central bank is following the Taylor rule, so they try to exactly offset the deflation by setting nominal interest rates very low. Real interest rate follows the Fisher equation $\\mathbb{E}\\left[\\hat{r}_t\\right] = \\hat{i}_t - \\mathbb{E}\\left[\\hat{\\pi}_{t+1}\\right]$, so the inflation dampens but doesn't totally offset the effect of the lower interest rate on real interest rate.\n",
    "\n",
    "$\\theta = 0.9999$: this is the case of almost perfectly sticky prices, so virtually no firms are allowed to adjust in response to the shock. The stuck prices means stuck consumption demand and therefore stuck output and a huge negative output gap. The increased productivity does allow firms to hire less labor, so that's nice, I suppose. As for monetary things, stuck prices means inflation is mechanically zero, which means no interest rate response by the central bank.\n",
    "\n",
    "Qualitively, the in-between values of $\\theta$ give us impulse response functions that are in between the extremes, which is to be expected. Interestly, they tend to look more like the flexible prices case than the sticky prices case: even $\\theta = 0.75$ more closely resembles $\\theta = 0.0001$ than $\\theta = 0.9999$. I think the intuition here is that when firms adjust, they adjust *a lot* because they are forward-looking and want to compensate for the fact that they are rarely allowed to adjust; this means that, in the aggregate, prices adjust more than we might expect, given the stickiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) What would you expect to see from the same shock in an RBC model without capital? (No derivation should be necessary.)\n",
    "\n",
    "In an RBC model, shocks to productivity entirely drive business cycles. Perfect competition means that firms are price takers, and household optimal consumption decisions (e.g., labor–leisure) sets output and employment levels: this should, I think, mean that the impulse response functions will look approximately like the $\\theta = 0$ case; except for the monetary ones, of course, because prices never show up in the RBC model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
